# Time & Space Complexity Guide

A comprehensive guide to understanding **Time Complexity** and **Space Complexity** in algorithms â€” essential concepts for writing efficient code.

---

## ğŸ“š Table of Contents

- [What is Time Complexity?](#what-is-time-complexity)
- [What is Space Complexity?](#what-is-space-complexity)
- [Big-O Notation](#big-o-notation)
- [Common Time Complexities](#common-time-complexities)
- [Common Space Complexities](#common-space-complexities)
- [How to Analyze Complexity](#how-to-analyze-complexity)
- [Visual Comparison Chart](#visual-comparison-chart)
- [Real-World Algorithm Examples](#real-world-algorithm-examples)
- [Tips for Optimization](#tips-for-optimization)
- [Quick Reference Cheat Sheet](#quick-reference-cheat-sheet)

---

## What is Time Complexity?

**Time Complexity** measures how the **runtime** of an algorithm grows as the input size increases.

It answers the question: *"How much longer will my algorithm take if I double the input size?"*

### Key Points:
- We measure the **number of operations**, not actual time (seconds)
- We focus on the **worst-case scenario** (unless specified otherwise)
- We care about **growth rate** as input becomes very large

### Diagram: Time vs Input Size

```
Runtime
   â–²
   â”‚                                          â•± O(nÂ²)
   â”‚                                        â•±
   â”‚                                      â•±
   â”‚                                   â•±
   â”‚                               â•±
   â”‚                          â•±        _____ O(n log n)
   â”‚                     â•±     _______
   â”‚               â•±  _______            _____ O(n)
   â”‚          â•± ____                ____
   â”‚     â•±____               ______
   â”‚ ____           _________           _____ O(log n)
   â”‚___________________________________________O(1)
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Input Size (n)
```

---

## What is Space Complexity?

**Space Complexity** measures how much **extra memory** an algorithm uses as input size grows.

It answers the question: *"How much additional memory does my algorithm need?"*

### Key Points:
- We measure **auxiliary space** (extra space beyond input)
- Input space is sometimes included (total space complexity)
- In-place algorithms have O(1) auxiliary space

### Diagram: Memory Allocation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  MEMORY                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Input Array   â”‚  â”‚  Auxiliary/Extra Space  â”‚ â”‚
â”‚  â”‚    O(n)       â”‚  â”‚     (what we count)     â”‚ â”‚
â”‚  â”‚               â”‚  â”‚                         â”‚ â”‚
â”‚  â”‚ [1,2,3,4,5]   â”‚  â”‚  variables, temp arrays â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Big-O Notation

**Big-O** describes the **upper bound** of an algorithm's growth rate.

### Common Notations:

| Notation     | Name           | Description                              |
|--------------|----------------|------------------------------------------|
| O(1)         | Constant       | Same time regardless of input size       |
| O(log n)     | Logarithmic    | Halves the problem each step             |
| O(n)         | Linear         | Grows proportionally with input          |
| O(n log n)   | Linearithmic   | Slightly worse than linear               |
| O(nÂ²)        | Quadratic      | Nested loops over input                  |
| O(nÂ³)        | Cubic          | Triple nested loops                      |
| O(2â¿)        | Exponential    | Doubles with each additional input       |
| O(n!)        | Factorial      | All permutations                         |

### Other Notations:

| Notation | Meaning                              |
|----------|--------------------------------------|
| Î© (Omega)| Lower bound (best case)              |
| Î˜ (Theta)| Tight bound (average case)           |
| O (Big-O)| Upper bound (worst case) â€” most used |

---

## Common Time Complexities

### O(1) â€” Constant Time

```
Operation count stays the same regardless of input size.
```

**Examples:**
- Array access by index: `arr[5]`
- Hash table lookup (average)
- Push/pop from stack

```
Input Size:    10      100      1000     10000
Operations:     1        1         1         1
                â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬
```

**Code Example (Go):**
```go
func getFirst(arr []int) int {
    return arr[0]  // Always 1 operation
}
```

---

### O(log n) â€” Logarithmic Time

```
Problem size is halved each iteration.
```

**Examples:**
- Binary search
- Finding element in balanced BST
- Exponentiation by squaring

```
Input Size:    10      100      1000     10000
Operations:     3        7        10        13
                â–¬â–¬â–¬      â–¬â–¬â–¬â–¬â–¬â–¬â–¬  â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬ â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬
```

**Visual: How Binary Search Halves**
```
Array: [1, 3, 5, 7, 9, 11, 13, 15]   Target: 11

Step 1: [1, 3, 5, 7, 9, 11, 13, 15]
                  â–² mid=7, 11>7, go right

Step 2:          [9, 11, 13, 15]
                      â–² mid=11, FOUND!

Only 2 steps for 8 elements! logâ‚‚(8) = 3 max steps
```

**Code Example (Go):**
```go
func binarySearch(arr []int, target int) int {
    left, right := 0, len(arr)-1
    for left <= right {
        mid := (left + right) / 2
        if arr[mid] == target {
            return mid
        } else if arr[mid] < target {
            left = mid + 1
        } else {
            right = mid - 1
        }
    }
    return -1
}
```

---

### O(n) â€” Linear Time

```
Operations grow directly proportional to input size.
```

**Examples:**
- Iterating through an array once
- Finding max/min element
- Linear search

```
Input Size:    10      100      1000     10000
Operations:    10      100      1000     10000
               â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬
                        â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬â–¬
```

**Code Example (Go):**
```go
func findMax(arr []int) int {
    max := arr[0]
    for _, val := range arr {  // n iterations
        if val > max {
            max = val
        }
    }
    return max
}
```

---

### O(n log n) â€” Linearithmic Time

```
Slightly worse than linear, but much better than quadratic.
```

**Examples:**
- Merge sort
- Quick sort (average case)
- Heap sort

```
Input Size:    10      100      1000     10000
Operations:    33      664      9966    132877
```

**Visual: Merge Sort Divide & Conquer**
```
Level 0:    [8, 4, 2, 6, 5, 1, 7, 3]        â†’ n operations to merge
                    /            \
Level 1:    [8, 4, 2, 6]    [5, 1, 7, 3]    â†’ n operations to merge
              /      \        /      \
Level 2:  [8,4]    [2,6]  [5,1]    [7,3]    â†’ n operations to merge
           / \      / \    / \      / \
Level 3: [8] [4]  [2] [6] [5] [1]  [7] [3]  â†’ n operations to merge

logâ‚‚(n) levels Ã— n operations per level = O(n log n)
```

---

### O(nÂ²) â€” Quadratic Time

```
Operations grow as the square of input size.
```

**Examples:**
- Nested loops over same array
- Bubble sort
- Selection sort
- Insertion sort

```
Input Size:    10      100      1000     10000
Operations:   100    10000   1000000  100000000
```

**Visual: Why Nested Loops = nÂ²**
```
for i in range(n):        â”€â”
    for j in range(n):     â”‚ n Ã— n = nÂ²
        operation          â”‚
                          â”€â”˜

    jâ†’  0   1   2   3   4
i â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
â†“ â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚  â† 5 operations
0 â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
  â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚  â† 5 operations
1 â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
  â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚  â† 5 operations
2 â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
  â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚  â† 5 operations
3 â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
  â”‚ x â”‚ x â”‚ x â”‚ x â”‚ x â”‚  â† 5 operations
4 â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜
        Total: 5 Ã— 5 = 25 = nÂ²
```

**Code Example (Go):**
```go
func bubbleSort(arr []int) {
    n := len(arr)
    for i := 0; i < n; i++ {           // n times
        for j := 0; j < n-i-1; j++ {   // n times (roughly)
            if arr[j] > arr[j+1] {
                arr[j], arr[j+1] = arr[j+1], arr[j]
            }
        }
    }
}
```

---

### O(2â¿) â€” Exponential Time

```
Operations double with each additional input element.
```

**Examples:**
- Recursive Fibonacci (naive)
- Power set generation
- Traveling salesman (brute force)

```
Input Size:    10      20       30        40
Operations:  1024   1048576  ~1 billion  ~1 trillion
```

**Visual: Fibonacci Recursion Tree**
```
                        fib(5)
                       /      \
                   fib(4)      fib(3)
                  /    \       /    \
              fib(3)  fib(2) fib(2) fib(1)
              /   \
          fib(2) fib(1)

Each level doubles the calls â†’ 2â¿ total calls
```

---

## Common Space Complexities

### O(1) â€” Constant Space

```go
func sum(arr []int) int {
    total := 0           // Just one variable
    for _, v := range arr {
        total += v
    }
    return total
}
// Space: O(1) - only 'total' variable, regardless of input size
```

### O(n) â€” Linear Space

```go
func duplicate(arr []int) []int {
    result := make([]int, len(arr))  // New array of size n
    for i, v := range arr {
        result[i] = v
    }
    return result
}
// Space: O(n) - result array grows with input
```

### O(nÂ²) â€” Quadratic Space

```go
func createMatrix(n int) [][]int {
    matrix := make([][]int, n)
    for i := 0; i < n; i++ {
        matrix[i] = make([]int, n)  // n arrays of size n
    }
    return matrix
}
// Space: O(nÂ²) - nÃ—n matrix
```

---

## How to Analyze Complexity

### Step-by-Step Guide:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. IDENTIFY THE INPUT                                       â”‚
â”‚     What is 'n'? (array length, string length, etc.)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  2. COUNT THE OPERATIONS                                     â”‚
â”‚     - Single operation = O(1)                                â”‚
â”‚     - Loop from 0 to n = O(n)                               â”‚
â”‚     - Nested loops = multiply their complexities            â”‚
â”‚     - Recursive calls = count total calls                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  3. FIND THE DOMINANT TERM                                   â”‚
â”‚     O(nÂ² + n + 1) â†’ O(nÂ²)  (drop lower terms)               â”‚
â”‚     O(3n) â†’ O(n)           (drop constants)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  4. IDENTIFY SPACE USAGE                                     â”‚
â”‚     - Count extra variables = O(1)                          â”‚
â”‚     - New array of size n = O(n)                            â”‚
â”‚     - Recursive call stack = O(depth)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example Analysis:

```go
func example(arr []int) int {
    n := len(arr)               // O(1)
    sum := 0                    // O(1)
    
    for i := 0; i < n; i++ {    // O(n)
        sum += arr[i]           //   â””â”€ O(1) per iteration
    }
    
    for i := 0; i < n; i++ {    // O(n)
        for j := 0; j < n; j++ {//   â””â”€ O(n) per iteration
            sum += arr[i]*arr[j]//       â””â”€ O(1)
        }
    }
    
    return sum                  // O(1)
}

// Time:  O(1) + O(1) + O(n) + O(nÂ²) + O(1)
//      = O(nÂ²)  â† dominant term
//
// Space: O(1)  â† only using n, sum, i, j (constant)
```

---

## Visual Comparison Chart

### Time Complexity Growth (for n = 1000):

```
O(1)        â”‚â–Œ                                              1
O(log n)    â”‚â–Œâ–Œ                                            10
O(n)        â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       1,000
O(n log n)  â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      10,000
O(nÂ²)       â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ...  1,000,000
O(2â¿)       â”‚ OVERFLOW - astronomically large
```

### Practical Time Limits:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Complexity â”‚ Max n       â”‚ Typical Use Case              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ O(n!)      â”‚ â‰¤ 10        â”‚ Permutations, brute force     â”‚
â”‚ O(2â¿)      â”‚ â‰¤ 20-25     â”‚ Subsets, recursive backtrack  â”‚
â”‚ O(nÂ³)      â”‚ â‰¤ 500       â”‚ Floyd-Warshall, 3D DP         â”‚
â”‚ O(nÂ²)      â”‚ â‰¤ 5,000     â”‚ Simple DP, brute comparisons  â”‚
â”‚ O(n log n) â”‚ â‰¤ 1,000,000 â”‚ Sorting, divide & conquer     â”‚
â”‚ O(n)       â”‚ â‰¤ 10â¸       â”‚ Single pass, linear scan      â”‚
â”‚ O(log n)   â”‚ â‰¤ 10Â¹â¸      â”‚ Binary search, exponentiation â”‚
â”‚ O(1)       â”‚ Any         â”‚ Math formula, hash lookup     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Real-World Algorithm Examples

### Example 1: Array Sum â€” O(n) Time, O(1) Space

```
Problem: Calculate the sum of all elements in an array
Approach: Single pass through array

total = 0
for each element:          â”€â”
    total += element        â”‚  n iterations
                           â”€â”˜

Time:  O(n) - one loop through all elements
Space: O(1) - just a single accumulator variable
```

**Code:**
```go
func arraySum(arr []int) int {
    total := 0
    for _, v := range arr {
        total += v
    }
    return total
}
```

### Example 2: Two Sum (Brute Force) â€” O(nÂ²) Time, O(1) Space

```
Problem: Find two numbers that add up to target
Approach: Check every pair of elements

for i in range(n):         â”€â”
    for j in range(i+1, n): â”‚  n Ã— n iterations
        if arr[i]+arr[j]==t â”‚
            return (i, j)  â”€â”˜

Time:  O(nÂ²) - nested loops checking all pairs
Space: O(1) - only index variables
```

**Code:**
```go
func twoSumBruteForce(arr []int, target int) (int, int) {
    n := len(arr)
    for i := 0; i < n; i++ {
        for j := i + 1; j < n; j++ {
            if arr[i]+arr[j] == target {
                return i, j
            }
        }
    }
    return -1, -1
}
```

### Example 3: Two Sum (Optimized) â€” O(n) Time, O(n) Space

```
Problem: Same as above, but optimized with hash map
Approach: Store seen values in a map

map = {}
for i, val in array:       â”€â”
    complement = target-val â”‚
    if complement in map:   â”‚  n iterations
        return result       â”‚
    map[val] = i           â”€â”˜

Time:  O(n) - single pass with O(1) hash lookups
Space: O(n) - hash map stores up to n elements
```

**Code:**
```go
func twoSumOptimized(arr []int, target int) (int, int) {
    seen := make(map[int]int)
    for i, val := range arr {
        complement := target - val
        if j, exists := seen[complement]; exists {
            return j, i
        }
        seen[val] = i
    }
    return -1, -1
}
```

### Example 4: Binary Search â€” O(log n) Time, O(1) Space

```
Problem: Find target in sorted array
Approach: Eliminate half of remaining elements each step

left, right = 0, n-1
while left <= right:       â”€â”
    mid = (left+right)/2    â”‚  logâ‚‚(n) iterations
    if arr[mid] == target:  â”‚
        return mid          â”‚
    elif arr[mid] < target: â”‚
        left = mid + 1      â”‚
    else:                   â”‚
        right = mid - 1    â”€â”˜

Time:  O(log n) - halves search space each iteration
Space: O(1) - only three pointer variables
```

### Example 5: Merge Sort â€” O(n log n) Time, O(n) Space

```
Problem: Sort an array
Approach: Divide and conquer with merging

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  divide array into halves  â†’ log n levels  â”‚
â”‚  merge sorted halves       â†’ n work/level  â”‚
â”‚                                            â”‚
â”‚  Total: O(n) Ã— O(log n) = O(n log n)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Time:  O(n log n) - divide (log n) Ã— merge (n)
Space: O(n) - temporary arrays for merging
```

### Example 6: Fibonacci (Naive Recursive) â€” O(2â¿) Time, O(n) Space

```
Problem: Calculate nth Fibonacci number
Approach: Recursive calls without memoization

fib(n) = fib(n-1) + fib(n-2)

                fib(5)
               /      \
           fib(4)    fib(3)    â† Same subproblems
          /    \      /    \      recalculated!
       fib(3) fib(2) fib(2) fib(1)

Time:  O(2â¿) - exponential recursive calls
Space: O(n) - recursion stack depth
```

### Example 7: Fibonacci (DP Optimized) â€” O(n) Time, O(1) Space

```
Problem: Same, but with dynamic programming
Approach: Track only previous two values

prev2, prev1 = 0, 1
for i in range(2, n+1):    â”€â”
    current = prev1 + prev2 â”‚  n iterations
    prev2 = prev1           â”‚
    prev1 = current        â”€â”˜

Time:  O(n) - single loop
Space: O(1) - only two/three variables
```

**Code:**
```go
func fibOptimized(n int) int {
    if n <= 1 {
        return n
    }
    prev2, prev1 := 0, 1
    for i := 2; i <= n; i++ {
        current := prev1 + prev2
        prev2 = prev1
        prev1 = current
    }
    return prev1
}
```

### Complexity Comparison Summary:

| Algorithm              | Time       | Space  | Trade-off                       |
|------------------------|------------|--------|----------------------------------|
| Array Sum              | O(n)       | O(1)   | Optimal                         |
| Two Sum (Brute)        | O(nÂ²)      | O(1)   | Simple, slow                    |
| Two Sum (Hash)         | O(n)       | O(n)   | Fast, uses memory               |
| Binary Search          | O(log n)   | O(1)   | Requires sorted input           |
| Merge Sort             | O(n log n) | O(n)   | Stable, consistent              |
| Fibonacci (Naive)      | O(2â¿)      | O(n)   | Don't use this!                 |
| Fibonacci (DP)         | O(n)       | O(1)   | Optimal                         |

---

## Tips for Optimization

### Time Optimization:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. AVOID NESTED LOOPS when possible                    â”‚
â”‚     O(nÂ²) â†’ O(n) using hash maps                        â”‚
â”‚                                                         â”‚
â”‚  2. USE BINARY SEARCH on sorted data                    â”‚
â”‚     O(n) â†’ O(log n)                                     â”‚
â”‚                                                         â”‚
â”‚  3. PRECOMPUTE values you'll use repeatedly             â”‚
â”‚     Calculate once, use many times                      â”‚
â”‚                                                         â”‚
â”‚  4. CHOOSE RIGHT DATA STRUCTURE                         â”‚
â”‚     Array lookup: O(1)                                  â”‚
â”‚     Hash map lookup: O(1) average                       â”‚
â”‚     Tree search: O(log n)                               â”‚
â”‚                                                         â”‚
â”‚  5. USE DYNAMIC PROGRAMMING                             â”‚
â”‚     Avoid recalculating same subproblems                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Space Optimization:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. MODIFY IN-PLACE when possible                       â”‚
â”‚     Don't create new arrays                             â”‚
â”‚                                                         â”‚
â”‚  2. USE VARIABLES instead of arrays for tracking        â”‚
â”‚     prev, curr instead of dp[]                          â”‚
â”‚                                                         â”‚
â”‚  3. PROCESS STREAMING data                              â”‚
â”‚     Don't store what you don't need                     â”‚
â”‚                                                         â”‚
â”‚  4. REUSE MEMORY                                        â”‚
â”‚     Clear and reuse instead of reallocating             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Quick Reference Cheat Sheet

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                 TIME COMPLEXITY CHEAT SHEET                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  O(1)       â”‚ Hash lookup, array access, math operations      â•‘
â•‘  O(log n)   â”‚ Binary search, balanced tree operations         â•‘
â•‘  O(n)       â”‚ Linear search, single loop, array traversal     â•‘
â•‘  O(n log n) â”‚ Efficient sorts (merge, quick, heap)            â•‘
â•‘  O(nÂ²)      â”‚ Nested loops, simple sorts (bubble, insertion)  â•‘
â•‘  O(2â¿)      â”‚ Recursive subsets, naive Fibonacci              â•‘
â•‘  O(n!)      â”‚ Permutations, traveling salesman brute force    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                 SPACE COMPLEXITY CHEAT SHEET                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  O(1)       â”‚ Fixed variables, in-place algorithms            â•‘
â•‘  O(log n)   â”‚ Recursive call stack (balanced recursion)       â•‘
â•‘  O(n)       â”‚ Linear data structures, 1D DP arrays            â•‘
â•‘  O(nÂ²)      â”‚ 2D matrices, adjacency matrix                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                      QUICK RULES                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  â€¢ Drop constants: O(3n) â†’ O(n)                               â•‘
â•‘  â€¢ Drop lower terms: O(nÂ² + n) â†’ O(nÂ²)                        â•‘
â•‘  â€¢ Nested loops multiply: O(n) Ã— O(m) = O(nÃ—m)                â•‘
â•‘  â€¢ Sequential code adds: O(n) + O(m) = O(n+m)                 â•‘
â•‘  â€¢ Recursive: count calls Ã— work per call                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ¯ Understanding Through Real-Life Analogies

### O(1) â€” Constant Time: Like a Light Switch
```
Turning on a light takes the same time whether your house has 
1 room or 100 rooms. You just flip the switch!

ğŸ  1 room    â†’ flip switch â†’ ğŸ’¡ instant
ğŸ¢ 100 rooms â†’ flip switch â†’ ğŸ’¡ instant

Real Examples:
â€¢ Looking up a contact by their saved position in your phone
â€¢ Opening a locker with its number
â€¢ Pressing elevator button for your floor
```

### O(log n) â€” Logarithmic Time: Like Finding a Word in Dictionary
```
When you search for "Python" in a dictionary:
1. Open middle â†’ "M" â€” Python comes after M, ignore first half
2. Open middle of remaining â†’ "R" â€” Python comes before R
3. Open middle of remaining â†’ "P" â€” Getting close!
4. Found "Python"!

ğŸ“– 1,000 pages â†’ ~10 steps
ğŸ“– 1,000,000 pages â†’ ~20 steps

You HALVE the problem each time!
```

### O(n) â€” Linear Time: Like Reading a Book
```
To read a 100-page book, you read 100 pages.
To read a 500-page book, you read 500 pages.

ğŸ“• 100 pages â†’ 100 minutes (1 page/min)
ğŸ“š 500 pages â†’ 500 minutes

Time grows DIRECTLY with input size.
```

### O(nÂ²) â€” Quadratic Time: Like Handshakes at a Party
```
If everyone at a party must shake hands with everyone else:

ğŸ‘¥ 5 people  â†’ 10 handshakes  (5Ã—4/2)
ğŸ‘¥ 10 people â†’ 45 handshakes  (10Ã—9/2)
ğŸ‘¥ 100 people â†’ 4,950 handshakes!

Each new person shakes hands with ALL existing people.
```

### O(2â¿) â€” Exponential Time: Like the Rice & Chessboard Story
```
Legend: A king offered to pay with rice on a chessboard:
â€¢ Square 1: 1 grain
â€¢ Square 2: 2 grains
â€¢ Square 3: 4 grains
â€¢ ...doubling each square

ğŸŒ¾ Square 10: 512 grains
ğŸŒ¾ Square 20: 524,288 grains
ğŸŒ¾ Square 64: 9,223,372,036,854,775,808 grains!

This is why exponential algorithms become impossible quickly.
```

---

## ğŸ§  Mental Models for Quick Analysis

### The Loop Counting Method

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  COUNT YOUR LOOPS - Quick Mental Calculation                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  No loops            â†’ O(1)                                  â”‚
â”‚  1 loop (0 to n)     â†’ O(n)                                  â”‚
â”‚  2 nested loops      â†’ O(nÂ²)                                 â”‚
â”‚  3 nested loops      â†’ O(nÂ³)                                 â”‚
â”‚  Loop halving        â†’ O(log n)                              â”‚
â”‚  Loop + halving      â†’ O(n log n)                            â”‚
â”‚                                                              â”‚
â”‚  EXAMPLE ANALYSIS:                                           â”‚
â”‚                                                              â”‚
â”‚  for i := 0; i < n; i++ {           â† 1 loop = O(n)         â”‚
â”‚      for j := 0; j < n; j++ {       â† nested = O(nÂ²)        â”‚
â”‚          for k := 0; k < n; k++ {   â† triple = O(nÂ³)        â”‚
â”‚              // operation                                    â”‚
â”‚          }                                                   â”‚
â”‚      }                                                       â”‚
â”‚  }                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The "What Happens When Input Doubles?" Test

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  If n doubles, how does time change?                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Stays same      â†’ O(1)     constant                        â”‚
â”‚  Adds a step     â†’ O(log n) logarithmic                     â”‚
â”‚  Doubles         â†’ O(n)     linear                          â”‚
â”‚  Bit more than 2xâ†’ O(n log n) linearithmic                  â”‚
â”‚  Quadruples (4x) â†’ O(nÂ²)    quadratic                       â”‚
â”‚  Squares itself  â†’ O(2â¿)    exponential                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

EXAMPLE:
If sorting 1000 items takes 1 second...
â€¢ O(n): 2000 items â†’ ~2 seconds
â€¢ O(nÂ²): 2000 items â†’ ~4 seconds
â€¢ O(n log n): 2000 items â†’ ~2.2 seconds
```

---

## ğŸ“Š Complexity Analysis by Code Pattern

### Pattern 1: Simple Iteration
```go
// O(n) Time, O(1) Space
for i := 0; i < n; i++ {
    // O(1) operation
}
```

### Pattern 2: Nested Loops (Same Range)
```go
// O(nÂ²) Time, O(1) Space
for i := 0; i < n; i++ {
    for j := 0; j < n; j++ {
        // O(1) operation
    }
}
```

### Pattern 3: Nested Loops (Different Range)
```go
// O(n Ã— m) Time, O(1) Space
for i := 0; i < n; i++ {
    for j := 0; j < m; j++ {
        // O(1) operation
    }
}
```

### Pattern 4: Loop with Halving
```go
// O(log n) Time, O(1) Space
for i := n; i > 0; i = i / 2 {
    // O(1) operation
}
```

### Pattern 5: Loop with Inner Halving
```go
// O(n log n) Time, O(1) Space
for i := 0; i < n; i++ {
    for j := n; j > 0; j = j / 2 {
        // O(1) operation
    }
}
```

### Pattern 6: Two Pointers
```go
// O(n) Time, O(1) Space
left, right := 0, n-1
for left < right {
    // O(1) operation
    left++   // or right--
}
```

### Pattern 7: Sliding Window
```go
// O(n) Time, O(1) Space
for right := 0; right < n; right++ {
    // expand window
    for /* window invalid */ {
        left++  // shrink window
    }
}
```

### Pattern 8: Recursive with Branching
```go
// O(2â¿) Time, O(n) Space (call stack)
func recursive(n int) int {
    if n <= 1 {
        return n
    }
    return recursive(n-1) + recursive(n-2)
}
```

### Pattern 9: Recursive with Single Branch
```go
// O(n) Time, O(n) Space (call stack)
func recursive(n int) int {
    if n <= 0 {
        return 0
    }
    return 1 + recursive(n-1)
}
```

### Pattern 10: Divide and Conquer
```go
// O(n log n) Time, O(n) Space
func divideConquer(arr []int) {
    if len(arr) <= 1 {
        return
    }
    mid := len(arr) / 2
    divideConquer(arr[:mid])   // log n levels
    divideConquer(arr[mid:])   // log n levels
    merge(arr)                  // O(n) work per level
}
```

---

## ğŸ“ Interview Tips & Common Questions

### How to Explain Complexity in Interviews

```
FORMULA FOR EXPLAINING:
"The time complexity is O(___) because [reason], 
and the space complexity is O(___) because [reason]."

GOOD ANSWER EXAMPLE:
"The time complexity is O(n) because we iterate through the array 
once, and each operation inside the loop is O(1). The space 
complexity is O(1) because we only use a constant number of 
variables regardless of input size."
```

### Common Interview Questions & Answers

**Q: "Can you optimize this O(nÂ²) solution?"**
```
THINK ABOUT:
â€¢ Can I use a hash map? â†’ Often reduces to O(n)
â€¢ Is the input sorted? â†’ Binary search gives O(log n)
â€¢ Can I use two pointers? â†’ Often O(n)
â€¢ Can I precompute something? â†’ Trade space for time
```

**Q: "What's the trade-off between time and space?"**
```
ANSWER FRAMEWORK:
"We can often trade space for time. For example, using a hash map 
takes O(n) extra space but reduces time from O(nÂ²) to O(n). 
The right choice depends on constraints - if memory is limited, 
we might accept slower time; if speed is critical, we use more space."
```

**Q: "Why is O(n log n) the best for comparison-based sorting?"**
```
ANSWER:
"Any comparison-based sorting algorithm must make at least 
logâ‚‚(n!) comparisons to distinguish between n! possible 
orderings. By Stirling's approximation, this is Î©(n log n). 
Therefore, O(n log n) is optimal for comparison sorts."
```

### Complexity of Common Operations

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    DATA STRUCTURE OPERATIONS                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ARRAY                                                         â•‘
â•‘  â”œâ”€ Access by index      O(1)                                  â•‘
â•‘  â”œâ”€ Search (unsorted)    O(n)                                  â•‘
â•‘  â”œâ”€ Search (sorted)      O(log n) with binary search           â•‘
â•‘  â”œâ”€ Insert at end        O(1) amortized                        â•‘
â•‘  â”œâ”€ Insert at beginning  O(n)                                  â•‘
â•‘  â””â”€ Delete               O(n)                                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  HASH MAP / HASH TABLE                                         â•‘
â•‘  â”œâ”€ Access               O(1) average, O(n) worst              â•‘
â•‘  â”œâ”€ Search               O(1) average, O(n) worst              â•‘
â•‘  â”œâ”€ Insert               O(1) average, O(n) worst              â•‘
â•‘  â””â”€ Delete               O(1) average, O(n) worst              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  LINKED LIST                                                   â•‘
â•‘  â”œâ”€ Access               O(n)                                  â•‘
â•‘  â”œâ”€ Search               O(n)                                  â•‘
â•‘  â”œâ”€ Insert at head       O(1)                                  â•‘
â•‘  â”œâ”€ Insert at tail       O(1) with tail pointer, O(n) without  â•‘
â•‘  â””â”€ Delete               O(1) if node known, O(n) to find      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  BINARY SEARCH TREE (BALANCED)                                 â•‘
â•‘  â”œâ”€ Access               O(log n)                              â•‘
â•‘  â”œâ”€ Search               O(log n)                              â•‘
â•‘  â”œâ”€ Insert               O(log n)                              â•‘
â•‘  â””â”€ Delete               O(log n)                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  HEAP / PRIORITY QUEUE                                         â•‘
â•‘  â”œâ”€ Find min/max         O(1)                                  â•‘
â•‘  â”œâ”€ Insert               O(log n)                              â•‘
â•‘  â”œâ”€ Delete min/max       O(log n)                              â•‘
â•‘  â””â”€ Build heap           O(n)                                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  STACK / QUEUE                                                 â•‘
â•‘  â”œâ”€ Push/Enqueue         O(1)                                  â•‘
â•‘  â”œâ”€ Pop/Dequeue          O(1)                                  â•‘
â•‘  â””â”€ Peek                 O(1)                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Sorting Algorithm Comparison

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    SORTING ALGORITHMS                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Algorithm      â•‘ Best      â•‘ Average   â•‘ Worst     â•‘ Space       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Bubble Sort    â•‘ O(n)      â•‘ O(nÂ²)     â•‘ O(nÂ²)     â•‘ O(1)        â•‘
â•‘ Selection Sort â•‘ O(nÂ²)     â•‘ O(nÂ²)     â•‘ O(nÂ²)     â•‘ O(1)        â•‘
â•‘ Insertion Sort â•‘ O(n)      â•‘ O(nÂ²)     â•‘ O(nÂ²)     â•‘ O(1)        â•‘
â•‘ Merge Sort     â•‘ O(n log n)â•‘ O(n log n)â•‘ O(n log n)â•‘ O(n)        â•‘
â•‘ Quick Sort     â•‘ O(n log n)â•‘ O(n log n)â•‘ O(nÂ²)     â•‘ O(log n)    â•‘
â•‘ Heap Sort      â•‘ O(n log n)â•‘ O(n log n)â•‘ O(n log n)â•‘ O(1)        â•‘
â•‘ Counting Sort  â•‘ O(n + k)  â•‘ O(n + k)  â•‘ O(n + k)  â•‘ O(k)        â•‘
â•‘ Radix Sort     â•‘ O(nk)     â•‘ O(nk)     â•‘ O(nk)     â•‘ O(n + k)    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•

k = range of input values (for counting/radix sort)
```

---

## ğŸ”¢ Mathematical Foundations

### Logarithm Basics (for log n understanding)

```
WHAT IS logâ‚‚(n)?
"How many times can you divide n by 2 until you reach 1?"

logâ‚‚(8) = 3   because 8 â†’ 4 â†’ 2 â†’ 1  (3 divisions)
logâ‚‚(16) = 4  because 16 â†’ 8 â†’ 4 â†’ 2 â†’ 1  (4 divisions)
logâ‚‚(1024) = 10

USEFUL TO REMEMBER:
logâ‚‚(1,000) â‰ˆ 10
logâ‚‚(1,000,000) â‰ˆ 20
logâ‚‚(1,000,000,000) â‰ˆ 30
```

### Summation Formulas

```
1 + 2 + 3 + ... + n = n(n+1)/2 â‰ˆ O(nÂ²)
   â””â”€â”€ Used in: nested loops where j goes from 0 to i

1 + 2 + 4 + ... + 2â¿ = 2â¿âºÂ¹ - 1 â‰ˆ O(2â¿)
   â””â”€â”€ Used in: exponential recursion

1 + 1/2 + 1/4 + ... = 2 â‰ˆ O(1)
   â””â”€â”€ Used in: geometric series that converge
```

### Recurrence Relations

```
COMMON RECURRENCES AND THEIR SOLUTIONS:

T(n) = T(n-1) + O(1)      â†’ O(n)         Linear recursion
T(n) = T(n-1) + O(n)      â†’ O(nÂ²)        Like selection sort
T(n) = T(n/2) + O(1)      â†’ O(log n)     Binary search
T(n) = T(n/2) + O(n)      â†’ O(n)         Like finding median
T(n) = 2T(n/2) + O(1)     â†’ O(n)         Tree traversal
T(n) = 2T(n/2) + O(n)     â†’ O(n log n)   Merge sort
T(n) = 2T(n-1) + O(1)     â†’ O(2â¿)        Fibonacci naive
```

---

## ğŸ§ª Practice Problems by Complexity

### O(1) Problems
- Check if a number is even/odd
- Swap two variables
- Access array element by index

### O(log n) Problems
- Binary search in sorted array
- Find first/last occurrence
- Search in rotated sorted array
- Find peak element

### O(n) Problems
- Find maximum/minimum in array
- Reverse an array
- Two Sum with hash map
- Valid parentheses (with stack)

### O(n log n) Problems
- Sort an array
- Find kth largest element
- Merge intervals
- Meeting rooms problem

### O(nÂ²) Problems
- Two Sum brute force
- Bubble/Selection/Insertion sort
- Find all pairs with given sum
- Check if array has duplicates (brute force)

---

## Further Reading

- [Big-O Cheat Sheet](https://www.bigocheatsheet.com/)
- [Visualizing Algorithms](https://visualgo.net/)
- [MIT OpenCourseWare - Introduction to Algorithms](https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-fall-2011/)

---

**Last Updated:** January 30, 2026
